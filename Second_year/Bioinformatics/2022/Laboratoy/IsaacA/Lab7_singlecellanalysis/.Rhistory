lines(x, fit2$fitted.values, col = 2, lwd = 3)
lines(x, fit2$fitted.values, col = 2, lwd = 3)
# example to show the power (reverse engeneering example) of models
# starting from the model
x <- seq(0, 10, 0.01)
x
length(x)
epsilon <- rnorm(101, mean = 0, sd = 1)  # random errors component
epsilon
length(epsilon)
# compute the mean of the response
mu <- 1 + x + cos(x)
mu    # these are the true value
y <- mu + epsilon
plot(y~x, lwd = 1)
lines(x, mu, lwd = 2) # true model
# with linear models you can model relationships that are not linear !!! WOW
fit2 <- lm(y~x+log(x+1))
summary(fit2)
lines(x, fit2$fitted.values, col = 2, lwd = 3)
fit3 <- lm(y~x+log(x+1)+sin(x))
summary(fit3)
fit3 <- lm(y~x+log(x+1)+cosin(x))
fit4 <- (y~x+cos(x))
summary(fit4)
fit4 <- lm(y~x+cos(x))
summary(fit4)
lines(x, fit2$fitted.values, col = 3, lwd = 3)
lines(x, fit4$fitted.values, col = 3, lwd = 3)
fit2 <- lm(y~x+log(x+1))
summary(fit2)  # significant
lines(x, fit2$fitted.values, col = 2, lwd = 3)
fit3 <- lm(y~x+log(x+1)+sin(x))
summary(fit3) # very bad
fit4 <- lm(y~x+cos(x))
summary(fit4)  # very significant
lines(x, fit4$fitted.values, col = 3, lwd = 3)
# example to show the power (reverse engeneering example) of models
# starting from the model
x <- seq(0, 10, 0.01)
x
length(x)
epsilon <- rnorm(101, mean = 0, sd = 1)  # random errors component
epsilon
length(epsilon)
# compute the mean of the response
mu <- 1 + x + cos(x)
mu    # these are the true value
y <- mu + epsilon
plot(y~x, lwd = 1)
lines(x, mu, lwd = 2) # true model
# with linear models you can model relationships that are not linear !!! WOW
fit2 <- lm(y~x+log(x+1))
summary(fit2)  # ok
lines(x, fit2$fitted.values, col = 2, lwd = 3)
fit3 <- lm(y~x+log(x+1)+sin(x))
summary(fit3) # very bad
fit4 <- lm(y~x+cos(x))
summary(fit4)  # very significant
lines(x, fit4$fitted.values, col = 3, lwd = 3)
summary(f)
f <- lm(y~x + cos(x) + sin(x) + exp(x) + I(x^2))   # I : makes it work as a transformat.
summary(f)
f.final <- step(f, .-.)
f.final <- step(f, ,-,)
f.final <- step(f, -)
f.final <- step(f, ~)
f.final <- step(f, .~.)
summary(f.final)
gc()
gc()
x <- rnorm(50)
x
qqnorm(x)
lines(x, col = 2)
lines(mean(x), col = 2)
x <- rnorm(50)
qqnorm(x)    # funtion specialized in normally distributed data
qqline(x)
x100.1 <- rnorm(100)
qqnorm(x100.1)
qqline(x100.1)
x100.2 <- rnorm(100)
qqnorm(x100.2)
qqline(x100.2)
x100.3 <- rnorm(100)
qqnorm(x100.3)
qqline(x100.3)
x100.1 <- rnorm(100)
qqnorm(x100.1)
qqline(x100.1)
x100.2 <- rnorm(100)
qqnorm(x100.2)
qqline(x100.2)
x100.3 <- rnorm(100)
qqnorm(x100.3)
qqline(x100.3)
x80 <- rnorm(80)
qqnorm(x80)
qqline(x80)
x70 <- rnorm(70)
qqnorm(x70)
qqline(x70)
x60 <- rnorm(60)
qqnorm(x60)
qqline(x60)
x20 <- rnorm(20)
qqnorm(x20)
qqline(x20)
x10 <- rnorm(10)
qqnorm(x10)
qqline(x10)
x15 <- rnorm(150)
qqnorm(x15)
qqline(x15)
x <- rnorm(50)
qqnorm(x)    # funtion specialized in normally distributed data
qqline(x)
# generate samples from the normal distr. like sample size 100 and ccompare them
x100.1 <- rnorm(100)
qqnorm(x100.1)
qqline(x100.1)
x100.2 <- rnorm(100)
qqnorm(x100.2)
qqline(x100.2)
x100.3 <- rnorm(100)
qqnorm(x100.3)
qqline(x100.3)
x80 <- rnorm(80)
qqnorm(x80)
qqline(x80)
x70 <- rnorm(70)
qqnorm(x70)
qqline(x70)
x60 <- rnorm(60)
qqnorm(x60)
qqline(x60)
x20 <- rnorm(20)
qqnorm(x20)
qqline(x20)
x10 <- rnorm(10)
qqnorm(x10)
qqline(x10)
x15 <- rnorm(15)
qqnorm(x15)
qqline(x15)
xt <- rnorm(100)
t(x)
t <- rt(100)
qqnorm(t, 5, 10)
t <- rt(100)
qqnorm(t, 5)
t <- rt(100)
qqnorm(t)
t <- rt(100)
qqnorm(t)
t <- rt(100)
qqnorm(t, 2)
t <- c(rt(100))
qqnorm(t, 2)
t <- rt(100, 2)
qqnorm(t)
t <- rt(100, 5)
qqnorm(t)
t <- rt(100, 10)
qqnorm(t)
t <- rt(100, 1)
qqnorm(t)
data(trees)
attach(trees)
pairs(trees)
fit <- lm(Volume~Girth+height)
fit <- lm(Volume~Girth+Height)
fit
summary(fit)
qqnorm(fit$residuals)
qqline(fit$residuals)
# test against the explanatory variables to test wether there are doubt about linearity
plot(fit$residuals~Girth)
abline(fit$residuals~Girth)
abline(fit$residuals~Girth)
abline(h = 0)
scatter.smooth(Girth, fit$residuals, col=2)
abline(h=0)
scatter.smooth(fit$fitted.values, fit$residuals, col=2)
abline(h=0)
fit1 <- lm(Volume~Girth+Girth^2+Height+Height^2)
qqnorm(fit$residuals)
qqline(fit$residuals
qqline(fit$residuals)
qqline(fit$residuals)
scatter.smooth(fit1$fitted.values, fit1$residuals, col=2)
fit1 <- lm(Volume~Girth+I(Girth^2)+Height+I(Height^2))
qqnorm(fit$residuals)
qqline(fit$residuals)
scatter.smooth(fit1$fitted.values, fit1$residuals, col=2) #
log2 <- lm(log(Volume)~log(Girth)+log(Height))
summary(log2)
log2 <- lm(log(Volume)~log(Girth)+log(Height))
qqnorm(fit2$residuals)
qqline(fit2$residuals)
# using the log that makes a multiplicative relation linear
log2 <- lm(log(Volume)~log(Girth)+log(Height))
qqnorm(log2$residuals)
qqline(log2$residuals)
fit2 <- lm(log(Volume)~log(Girth)+log(Height))
qqnorm(fit2$residuals)
qqline(fit2$residuals)
scatter.smooth(fit2$fitted.values, fit2$residuals, col=2)
abline(h=0)
summary(fit2)
library(faraway)
install(faraway)
install.packages(faraway)
install.packages(faraway)
install.packages('faraway')
library(faraway)
data(compilation)
library(faraway)
data(compilation)
data("composite")
head(completion)
library(faraway)
data(completion)
head(completion)
library(faraway)
data(coagulation)
head(coagulation)
summary(coagulation)
attach(coagulation)
plot(coag~diet)
contrasts(diet)
# has 4 level, and it creates 3 dummies called B, C, D
fit <- ln(coag~diet)
# has 4 level, and it creates 3 dummies called B, C, D
fit <- lm(coag~diet)
summary(fit)
plot(fit) # if you plot this object R propose some plots
plot(fit) # if you plot this object R propose some plots
# abused women
data(faraway)
# abused women
library(faraway)
data("sexab")
head(sexab)
summary(sexab)
attach(cpa)
attach(csa)
# abused women
library(faraway)
data("sexab")
head(sexab)
summary(sexab)
attach(csa)
# abused women
library(faraway)
data("sexab")
head(sexab)
summary(sexab)
# attach()
# conditional plot
coplot(ptsd~cpa, csa, sexab)
# conditional plot
coplot(ptsd~cpa|csa, sexab)
# conditional plot
coplot(ptsd~cpa|csa, panel = panel.smooth(), sexab)
# conditional plot
coplot(ptsd~cpa|csa, panel = panel.smooth(1), sexab)
# conditional plot
coplot(ptsd~cpa|csa, panel = panel.smooth, sexab)
detach(coagulation)
attach(sexab)
fit <- lm(ptsd~csa*cpa)
summary(fit)
contrasts(csa)
?IQR
y <- c(123, 117, 139, 132, 108, 127, 112, 113, 128, 119, 125, 117, 113, 120, 114, 132, 106)
# ?sort
yord = sort(y)
yord
# median
sum(yord[9:10]/2)
# first quantile
yord[1:9]   # order of observation
yord[5]
# third quantile
yord[10:18]
yord[14]
y <- c(123, 117, 139, 132, 108, 127, 112, 113, 128, 119, 125, 117, 113, 127, 120, 114, 132, 106)
# ?sort
yord = sort(y)
yord
# median
sum(yord[9:10]/2)
# first quantile
yord[1:9]   # order of observation
yord[5]
# third quantile
yord[10:18]
yord[14]
summary(y) # do the things we did before
hist(y)
boxplot(y)
IQR(y) # interquantile range
127+1.5*IQR(y)
112.8-1.5*IQR(y) # everything outside this range is considered an outlier (like 90 in this case)
147.625+13.75
147.625+13.75+13.75
147.625-13.75-13.75
147.625-13.75*3
147.625-13.75*4
qt(0.975)
qt(0.975, df=59)
179.3+2(7/sqrt(60))
179.3+2(7/(sqrt(60)))
179.3+2*(7/(sqrt(60)))
179.3-2*(7/(sqrt(60)))
qt(0.95, df=59)
179.3-1.67*(7/(sqrt(60)))
179.3+1.67*(7/(sqrt(60)))
179.3-2*(6/(sqrt(60)))
179.3+2*(6/(sqrt(60)))
(179.3-180)/(7/sqrt(60))
qt(-0.77, df=59)
qt(0.77, df=59)
1 - qt(0.77, df=59)
qnorm(-0.77)
qnorm(0.77)
1-qnorm(0.77)
qnorm(-0.77)
y <- c(123, 117, 139, 132, 108, 127, 112, 113, 128, 119, 125, 117, 127, 120, 114, 132, 106)
y
n <- length(y)
y <- c(123, 117, 139, 132, 108, 127, 112, 113, 128, 119, 125, 117, 113, 127, 120, 114, 132, 106)
n <- length(y)
sort(y)
y[9:10]
sort(y)[9:10]
# first quantile
sort(y)[5]
# third quantile  <- median of the obs ranked from 10 to 18
sort(y)[14]
summary(y)
plot(sort(y))
mean(y)
y_bar <- mean(y)
n*y_bar
prod(y)
qnorm(0.975)
qnorm(-0.51)
qt(-0.51, df = 17)
1 - 2*qt(0.51, df = 17)
2*pnorm(-0.51)
boxplot(y)
-(sum((y - a*mean(y))^2))/2*sigma_square
y <- c(13.2, 8.2, 10.9, 14.3, 10.7, 6.6, 9.5, 10.8, 8.8, 13.3)
a <- 2
sigma_square <- 15
-(sum((y - a*mean(y))^2))/2*sigma_square
mu.hat <- mean(y)/a
mu.hat
gc()
y <- c(2.6, -2.4, 0.3, 3.7, 0.1, -4.0, -1.1, 0.2, -1.8, 2.7)
x <- c(-3.9, 5.0, -5.2, 0.5)
sigma <- seq(0, 100, length=100)
sigma.hat <- 6.274
a <- 2
loglik <- function(theta){
-((1/2) * (length(x) + length(y)) * log(theta)) - (sum(x^2) + a*sum(y^2))/(2*a*theta)
}
norm_loglik <- vapply(sigma, loglik, numeric(1)) - loglik(sigma.hat)
plot(norm_loglik~sigma, type='l')
j <- ((length(x)+length(y))/(2*sigma.hat^2)) - (sum(x^2)- a*sum(y^2))/(a*sigma.hat^3)
par_approx <- -((sigma - sigma.hat)^2)/2 * j
lines(par_approx~sigma, col = 'red')
CI <- sigma.hat + 1.96*(sqrt((2*(sigma.hat^2)/(length(x)+length(y)))))
install.packages("Seurat")
library("Seurat")
setwd("C:\Users\Isaac\Desktop\Genomics\SecondYear\Bioinformatics\LABORATORY\Lab6_singlecellanalysis")
setwd("C:\Users\Isaac\Desktop\Genomics\SecondYear\Bioinformatics\LABORATORY\Lab6_singlecellanalysis")
setwd("C:\Users\Isaac\Desktop\Genomics\SecondYear\Bioinformatics\LABORATORY\Lab6_singlecellanalysis")
rawcounts <- read.delim("https://www.dropbox.com/s/3uz6txc5bs4kwlb/rawcounts.txt?dl=1")
# always first command for loading a matrix (table)
dim(rawcounts)
rawcounts[1:5,1:3]
# this doesn't work
setwd("C:/Users/Isaac/Desktop/Genomics/SecondYear/Bioinformatics/LABORATORY/Lab6_singlecellanalysis")
rawcounts<-read.delim("rawcounts.txt")
is.numeric(rawcounts)
is.data.frame(rawcounts)
# embed the object into a seurat object (for the same reason of the dataset thing we saw)
seuset <- CreateSeuratObject(counts = rawcounts)
seuset
rowcounts
rawcounts
str(seuset)
seuset@assays$RNA@counts
seuset@assays$RNA@counts@Dimnames[1]
# slide 45
# Normalize and Scale the gene expression raw count data
seuset <- NormalizeData(seuset)
seuset <- ScaleData(seuset)
seuset
str(seuset)
# Extract the normalized data
expmat<-seuset@assays$RNA@scale.data
str(expmat)
expmat
expmat[1:5,1:3]
expmat[1:5,1:3]     # expmat is the name used by USA for normalized and scaled data
ppp
ppp <- prcomp(t(expmat)) # t() is the transposed
plot(x,y)
# we can get the first two components
# components are the orientations giving the most variance
# the first two components by definition are those capturing the
x <- ppp$x[,1]
y <- ppp$x[,2]
plot(x,y)
x[1:3]
y[1:3]
plot(x,y, main = "single cell RNA-Seq - PCA projection")
# install and load Rtsne
install.packages("Rtsne")
install.packages("Rtsne")
library(Rtsne)
library(Rtsne)
ttt <- Rtsne(t(expmat))
# extract coordinates of cells
x <- ttt$Y[,1]
y <- ttt$Y[,2]
plot(x, y)
plot(x,y, main = "single cell RNA-Seq - PCA projection", xlabel="suca")
# single cell file reduced to get an easy download
install.packages("Seurat")
library("Seurat")
# set directory and create an object of the document
setwd("C:/Users/Isaac/Desktop/Genomics/SecondYear/Bioinformatics/LABORATORY/Lab6_singlecellanalysis")
rawcounts<-read.delim("rawcounts.txt")
# alternative
#rawcounts <- read.delim("https://www.dropbox.com/s/3uz6txc5bs4kwlb/rawcounts.txt?dl=1")
# always first command for loading a matrix (table)
dim(rawcounts)
head(rawcounts) # not good for wide matrices
rawcounts[1:5,1:3]  # splicing
# DEBUGGING ONLY
is.numeric(rawcounts) # False, because whenever you load a big file, it forms a dataframe which can contain a mixture of numbers, and strings
is.data.frame(rawcounts)
# embed the object into a Seurat object (for the same reason of the dataset thing we saw)
seuset <- CreateSeuratObject(counts = rawcounts)
rawcounts
seuset
str(seuset)
# as we can see, the count data is now a Sparse matrix
seuset@assays$RNA@counts  # dots became 0, it is more useful for compress it and easier to use for calculation
seuset@assays$RNA@counts@Dimnames[1]
# slide 45
# Normalize and Scale the gene expression raw count data
seuset <- NormalizeData(seuset) # normalization is necessary for most if not all downstream operations
seuset <- ScaleData(seuset)
seuset
str(seuset)
# Extract the normalized data
expmat<-seuset@assays$RNA@scale.data
expmat[1:5,1:3]     # expmat is the name used by USA for normalized and scaled data
# Principal Component Analysis
# we start with expmat
?prcomp
ppp <- prcomp(t(expmat)) # t() is the transpose function.
# ... si that PCA is done for visualizing cells, nor genes
ppp
str(ppp)
# we can get the first two components
# components are the orientations giving the most variance
# the first two components by definition are those capturing the
x <- ppp$x[,1]
y <- ppp$x[,2]
plot(x,y, main = "single cell RNA-Seq - PCA projection", xlabel="suca")
x[1:3]
y[1:3]
plot(x,y, main = "single cell RNA-Seq - PCA projection")
x[1,3]
x[1:3]
y[1:3]
set.seed(12345678)
ttt <- Rtsne(t(expmat))
# extract coordinates of cells
x <- ttt$Y[,1]
y <- ttt$Y[,2]
# Plot coordinates of cells
plot(x, y, main="TSNE") #TSNE is not pure deterministic, so you need to set seed
x[1:3]
y[1:3]
set.seed(12345678)
ttt <- Rtsne(t(expmat))
# extract coordinates of cells
x <- ttt$Y[,1]
y <- ttt$Y[,2]
# Plot coordinates of cells
plot(x, y, main="TSNE") #TSNE is not pure deterministic, so you need to set seed
x[1:3]
y[1:3]
set.seed(1)
ttt <- Rtsne(t(expmat))
# extract coordinates of cells
x <- ttt$Y[,1]
y <- ttt$Y[,2]
# Plot coordinates of cells
plot(x, y, main="TSNE") #TSNE is not pure deterministic, so you need to set seed
x[1:3]
y[1:3]
seuset@meta.data
